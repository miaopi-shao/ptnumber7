# -*- coding: utf-8 -*-
"""
Created on Sun Feb 23 17:08:53 2025

@author: OAP-0001
"""

# ========================================================
# A. è³‡æ–™åº«æ¨¡å‹éƒ¨åˆ†
# ========================================================

# A-1. åŒ¯å…¥å¿…è¦æ¨¡çµ„èˆ‡åˆå§‹åŒ–è³‡æ–™åº« (Flask SQLAlchemy)
from flask_sqlalchemy import SQLAlchemy                      # ç”¨æ–¼è™•ç†è³‡æ–™åº«æ“ä½œ
from datetime import datetime                                # è™•ç†æ—¥æœŸå’Œæ™‚é–“
from werkzeug.security import check_password_hash            # ç”¨æ–¼å¯†ç¢¼æ¯”å°

# A-2. å…¶ä»–å¤–éƒ¨æ¨¡çµ„ï¼ˆèˆ‡çˆ¬èŸ²ç›¸é—œï¼‰
import requests                                              # ç”¨æ–¼ç™¼é€ HTTP è«‹æ±‚
import os
from bs4 import BeautifulSoup                                # ç”¨æ–¼è§£æ HTML
import sqlite3                                               # ç”¨æ–¼ SQLite æ“ä½œ
import schedule                                              # ç”¨æ–¼å®šæ™‚ä»»å‹™æ’ç¨‹
import time                                                  # ç”¨æ–¼å®šæ™‚ä»»å‹™å»¶æ™‚
from fake_useragent import UserAgent                         # å‰µå»ºè™›æ“¬ç’°å¢ƒ

# A-3. åˆå§‹åŒ– SQLAlchemy è³‡æ–™åº«å°è±¡
db = SQLAlchemy()

# ------------------- ç”¨æˆ¶è³‡æ–™åº«æ¨¡å‹ -------------------
class User(db.Model):
    """ å®šç¾©ç”¨æˆ¶è³‡æ–™æ¨¡å‹ï¼Œç”¨æ–¼å­˜å„²ç”¨æˆ¶çš„å¸³è™Ÿã€å¯†ç¢¼ã€éƒµç®±ç­‰è³‡è¨Š """
    id = db.Column(db.Integer, primary_key=True)  # A-2-1: ä¸»éµï¼Œå”¯ä¸€è­˜åˆ¥ç”¨æˆ¶
    username = db.Column(db.String(100), unique=True, nullable=False)  # A-2-2: ç”¨æˆ¶åï¼Œå”¯ä¸€ä¸”ä¸å¯ç‚ºç©º
    password = db.Column(db.String(200), nullable=False)  # A-2-3: å¯†ç¢¼ï¼ˆå­˜æ”¾é›œæ¹Šå€¼ï¼‰ï¼Œä¸èƒ½ç‚ºç©º
    email = db.Column(db.String(120), unique=True, nullable=True)  # A-2-4: é›»å­éƒµä»¶ï¼Œå”¯ä¸€ï¼Œå¯é¸
    created_at = db.Column(db.DateTime, default=datetime.utcnow)  # A-2-5: ç”¨æˆ¶å‰µå»ºæ™‚é–“ï¼Œé è¨­ç‚ºç•¶å‰æ™‚é–“
    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)  # A-2-6: ç”¨æˆ¶è³‡æ–™æ›´æ–°æ™‚é–“ï¼Œè‡ªå‹•æ›´æ–°
    role = db.Column(db.String(20), default="user")  # A-2-7: ç”¨æˆ¶è§’è‰²ï¼Œé è¨­ç‚ºæ™®é€šç”¨æˆ¶

    # A-2-8: å®šç¾©ä¸€å€‹æ–¹æ³•æª¢æŸ¥å¯†ç¢¼æ˜¯å¦æ­£ç¢º
    def check_password(self, password):
        """ æª¢æŸ¥å¯†ç¢¼æ˜¯å¦æ­£ç¢º """
        return check_password_hash(self.password, password)

# ------------------- åˆ†æ•¸è³‡æ–™åº«æ¨¡å‹ -------------------
class Score(db.Model):
    """ å®šç¾©éŠæˆ²åˆ†æ•¸è³‡æ–™æ¨¡å‹ï¼Œç”¨æ–¼å­˜å„²ç”¨æˆ¶çš„éŠæˆ²åˆ†æ•¸ """
    id = db.Column(db.Integer, primary_key=True)  # A-3-1: ä¸»éµï¼Œå”¯ä¸€è­˜åˆ¥åˆ†æ•¸
    user_id = db.Column(db.Integer, db.ForeignKey('user.id'), nullable=False)  # A-3-2: èˆ‡ User æ¨¡å‹é—œè¯ (æ³¨æ„ï¼šè³‡æ–™è¡¨åç¨±é»˜èªç‚º user)
    game_name = db.Column(db.String(50), nullable=False)  # A-3-3: éŠæˆ²åç¨±
    score = db.Column(db.Integer, nullable=False)  # A-3-4: åˆ†æ•¸ï¼Œä¸èƒ½ç‚ºç©º
    created_at = db.Column(db.DateTime, default=datetime.utcnow)  # A-3-5: è¨˜éŒ„åˆ†æ•¸æ™‚é–“

# ========================================================
# B. Yahoo æ–°èçˆ¬èŸ²åŠè³‡æ–™å„²å­˜éƒ¨åˆ†
# ========================================================

# ------------------------------ã€Yahoo æ–°èçˆ¬èŸ²ã€‘------------------------
def fetch_yahoo_news():
    """
    B-1. Yahoo æ–°èçˆ¬èŸ² (æ“´å±•ç‰ˆ)
    - çˆ¬å–æ¨™é¡Œã€åœ–ç‰‡ã€å…§æ–‡ã€ä½œè€…ã€ç™¼å¸ƒæ™‚é–“ã€é€£çµ
    - è³‡æ–™å­˜å…¥ SQLite è³‡æ–™åº«
    """
    url = "https://tw.news.yahoo.com/"
    
    # åˆå§‹åŒ– UserAgent å®ä¾‹
    ua = UserAgent()
    # é¢„è®¾çš„ User-Agent
    default_headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    # å°è¯•ä½¿ç”¨éšæœº User-Agent

    # B-1-1: é¿å…å¤šé‡åŸ·è¡Œï¼Œä½¿ç”¨ lock æª”æ¡ˆæ§åˆ¶
    lock_file = "yahoo_news.lock"
    if os.path.exists(lock_file):
        print("âš ï¸ å…¶ä»–çˆ¬èŸ²æ­£åœ¨é‹è¡Œï¼Œè·³éæœ¬æ¬¡çˆ¬å–")
        return []
    open(lock_file, "w").close()  # å»ºç«‹ lock æª”

    try:
        random_headers = {
            "User-Agent": ua.random
        }
        response = requests.get(url, headers=random_headers, timeout=10)
        response.raise_for_status()
        return response
    except requests.RequestException as e:
        print(f"âŒ éš¨æ©ŸUser-Agentè«‹æ±‚å¤±æ•—: {e}")
        
        # åˆ é™¤é”æ–‡ä»¶
        try:
            os.remove(lock_file)
        except OSError as oe:
            print(f"âŒ åˆ é™¤é”æ–‡ä»¶å¤±è´¥: {oe}")
        # å°è¯•ä½¿ç”¨é¢„è®¾çš„ User-Agent
        try:
            response = requests.get(url, headers=default_headers, timeout=10)
            response.raise_for_status()
            return response
        except requests.RequestException as e:
            print(f"âŒ ä½¿ç”¨é¢„è®¾ User-Agent è¯·æ±‚å¤±è´¥: {e}")
            
            # åˆ é™¤é”æ–‡ä»¶
            try:
                os.remove(lock_file)
            except OSError as oe:
                print(f"âŒ åˆ é™¤é”æ–‡ä»¶å¤±è´¥: {oe}")
            return None
 
    
    # B-1-2: è§£æ HTML
    soup = BeautifulSoup(response.text, 'html.parser')
    # B-1-3: æ ¹æ“š HTML çµæ§‹æŠ“å–æ–°èå€å¡Š
    articles = soup.find_all('li', class_='js-stream-content')
    if not articles:
        print("âš ï¸ æ‰¾ä¸åˆ°æ–°èå€å¡Šï¼Œå¯èƒ½æ˜¯ HTML çµæ§‹è®Šæ›´")
        os.remove(lock_file)
        return []
    
    data_storage = []  # B-1-4: åˆå§‹åŒ–å„²å­˜è³‡æ–™åˆ—è¡¨
    
    # B-1-5: è¿´åœˆè™•ç†æ¯ç¯‡æ–°è
    for article in articles:
        title_tag = article.find('h3')
        a_tag = title_tag.find('a') if title_tag else None
        title = title_tag.get_text(strip=True) if title_tag else "ç„¡æ¨™é¡Œ"
        link = a_tag['href'] if a_tag and 'href' in a_tag.attrs else None
        if link and link.startswith('/'):
            link = "https://tw.news.yahoo.com" + link  # è™•ç†ç›¸å°è·¯å¾‘

        img_tag = article.find('img')
        image = img_tag['src'] if img_tag and 'src' in img_tag.attrs else None

        # B-1-6: çˆ¬å–æ–°èå…§é è©³ç´°å…§å®¹
        content, author, published_time = fetch_news_details(link) if link else (None, None, None)

        data_storage.append({
            'title': title,
            'image': image,
            'content': content,
            'author': author,
            'published_time': published_time,
            'url': link,
            'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })

    print(f"âœ… æˆåŠŸæŠ“å– {len(data_storage)} ç¯‡æ–°è")
    if data_storage:
        print("ğŸ“Œ æœ€å¾Œä¸€ç¯‡æ–°èè³‡æ–™ï¼š", data_storage[-1])
    
    os.remove(lock_file)  # B-1-7: ç§»é™¤ lock æª”
    return data_storage

def fetch_news_details(url):
    """
    B-2. é€²å…¥æ–°èå…§é ï¼Œçˆ¬å–å®Œæ•´å…§æ–‡ã€ä½œè€…èˆ‡ç™¼å¸ƒæ™‚é–“
    """
    if not url:
        return None, None, None

    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')

        # B-2-1: æŠ“å–å…§æ–‡ï¼ˆé€šå¸¸æ˜¯ <p> æ¨™ç±¤å…§çš„å…§å®¹ï¼‰
        paragraphs = soup.find_all('p')
        content = "\n".join([p.get_text(strip=True) for p in paragraphs]) if paragraphs else None

        # B-2-2: æŠ“å–ä½œè€…ï¼ˆæ ¹æ“š HTML çµæ§‹èª¿æ•´ï¼‰
        author_tag = soup.find('span', class_='caas-attr-author')
        author = author_tag.get_text(strip=True) if author_tag else "æœªçŸ¥ä½œè€…"

        # B-2-3: æŠ“å–ç™¼å¸ƒæ™‚é–“ï¼ˆé€šå¸¸åœ¨ <time> æ¨™ç±¤ï¼‰
        time_tag = soup.find('time')
        published_time = time_tag['datetime'] if time_tag and 'datetime' in time_tag.attrs else None

        return content, author, published_time
    except requests.RequestException as e:
        print(f"âŒ å…§é è«‹æ±‚å¤±æ•—: {e}")
        return None, None, None

def save_all_to_db(data_storage):
    """
    B-3. å°‡çˆ¬å–çš„æ–°èè³‡æ–™å­˜å…¥ SQLite è³‡æ–™åº«ï¼Œä¸¦ä¿ç•™æœ€æ–° 100 ç­†
    """
    try:
        conn = sqlite3.connect('news.db', timeout=30)
        cursor = conn.cursor()

        cursor.execute("PRAGMA journal_mode=WAL;")
        cursor.execute("PRAGMA synchronous=NORMAL;")
        cursor.execute("PRAGMA cache_size=-64000;")

        # B-3-1: å»ºç«‹æ–°èè³‡æ–™è¡¨ï¼ˆå¦‚æœå°šä¸å­˜åœ¨ï¼‰
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS news (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                image TEXT,
                content TEXT,
                author TEXT,
                published_time TEXT,
                url TEXT NOT NULL UNIQUE,
                date TEXT NOT NULL
            )
        ''')

        count = 0
        for data in data_storage:
            try:
                cursor.execute("INSERT OR REPLACE INTO news (title, image, content, author, published_time, url, date) VALUES (?, ?, ?, ?, ?, ?, ?)",
                               (data['title'], data['image'], data['content'], data['author'], data['published_time'], data['url'], data['date']))
                count += 1
            except sqlite3.IntegrityError:
                continue  # é¿å…é‡è¤‡è³‡æ–™

        # B-3-2: ä¿ç•™æœ€æ–° 100 ç­†è³‡æ–™ï¼Œå…¶é¤˜åˆªé™¤
        cursor.execute("DELETE FROM news WHERE id NOT IN (SELECT id FROM news ORDER BY date DESC LIMIT 100)")
        conn.commit()
        print(f"âœ… æˆåŠŸå­˜å…¥ {count} ç¯‡æ–°è")
    except sqlite3.OperationalError as e:
        print(f"âŒ è³‡æ–™åº«éŒ¯èª¤: {e}")
    finally:
        conn.close()

def fetch_and_save():
    """
    B-4. åŸ·è¡Œ Yahoo æ–°èçˆ¬èŸ²ä¸¦å°‡è³‡æ–™å­˜å…¥è³‡æ–™åº«
    """
    data_storage = fetch_yahoo_news()
    if data_storage:
        save_all_to_db(data_storage)

def schedule_task():
    """
    B-5. å®šæ™‚ä»»å‹™ï¼šæ¯å°æ™‚çˆ¬å–ä¸€æ¬¡ Yahoo æ–°è
    """
    schedule.every(1).hours.do(fetch_and_save)
    # B-5-1: é€²å…¥ç„¡é™å¾ªç’°ï¼Œå®šæ™‚åŸ·è¡Œçˆ¬èŸ²ä»»å‹™
    while True:
        schedule.run_pending()
        time.sleep(1)

# ========================================================
# C. ä¸»ç¨‹åºé‹è¡Œé †åº
# ========================================================

if __name__ == "__main__":
    # C-1: åˆæ¬¡åŸ·è¡Œçˆ¬èŸ²ï¼Œå–å¾—æ–°èè³‡æ–™ä¸¦å­˜å…¥è³‡æ–™åº«
    data = fetch_yahoo_news()
    if data:
        save_all_to_db(data)
    # C-2: é–‹å§‹å®šæ™‚ä»»å‹™ï¼ˆæ¯å°æ™‚åŸ·è¡Œä¸€æ¬¡çˆ¬èŸ²ï¼‰
    schedule_task()

"""
ã€æ•´é«”ç¨‹å¼é‹ä½œé †åºèªªæ˜ã€‘

A. è³‡æ–™åº«æ¨¡å‹éƒ¨åˆ†ï¼ˆA-1 ~ A-3ï¼‰
    A-1: åŒ¯å…¥å¿…è¦æ¨¡çµ„ä¸¦åˆå§‹åŒ–è³‡æ–™åº«
    A-2: å®šç¾© User æ¨¡å‹ï¼ˆç”¨æ–¼è™•ç†ç”¨æˆ¶è³‡æ–™èˆ‡å¯†ç¢¼é©—è­‰ï¼‰
    A-3: å®šç¾© Score æ¨¡å‹ï¼ˆç”¨æ–¼å„²å­˜éŠæˆ²åˆ†æ•¸ï¼‰

B. Yahoo æ–°èçˆ¬èŸ²éƒ¨åˆ†ï¼ˆB-1 ~ B-5ï¼‰
    B-1: fetch_yahoo_news()ï¼šçˆ¬å– Yahoo æ–°èåˆ—è¡¨èˆ‡åŸºæœ¬è³‡æ–™
    B-2: fetch_news_details(url)ï¼šé€²å…¥æ–°èå…§é çˆ¬å–å®Œæ•´å…§æ–‡ã€ä½œè€…ã€ç™¼å¸ƒæ™‚é–“
    B-3: save_all_to_db(data_storage)ï¼šå°‡çˆ¬å–çš„æ–°èè³‡æ–™å­˜å…¥ SQLite è³‡æ–™åº«ï¼Œä¸¦ä¿ç•™æœ€æ–° 100 ç­†
    B-4: fetch_and_save()ï¼šæ•´åˆçˆ¬èŸ²èˆ‡å­˜å„²åŠŸèƒ½
    B-5: schedule_task()ï¼šæ¯å°æ™‚å®šæ™‚åŸ·è¡Œçˆ¬èŸ²ä»»å‹™ï¼ˆä½µè¡ŒæŒçºŒé‹è¡Œï¼‰

C. ä¸»ç¨‹åºï¼ˆC-1, C-2ï¼‰
    C-1: åˆæ¬¡çˆ¬å–æ–°èè³‡æ–™ä¸¦å­˜å…¥è³‡æ–™åº«
    C-2: å•Ÿå‹• schedule_task() é€²å…¥å®šæ™‚çˆ¬èŸ²å¾ªç’°

ã€èˆ‡å…¶ä»–æª”æ¡ˆçš„è¯ç¹«ã€‘
- app.pyï¼šä½¿ç”¨ User èˆ‡ Score æ¨¡å‹è™•ç†ç”¨æˆ¶è¨»å†Šã€ç™»å…¥ã€æŸ¥è©¢èˆ‡éŠæˆ²åˆ†æ•¸å„²å­˜ã€‚
- auth.jsï¼šå‰ç«¯è™•ç†ç”¨æˆ¶è¨»å†Šã€ç™»å…¥ï¼Œé€é POST è«‹æ±‚èˆ‡å¾Œç«¯äº’å‹•ã€‚
- index.htmlï¼šå‰ç«¯é é¢é¡¯ç¤ºè¨»å†Šã€ç™»å…¥è¡¨å–®ï¼Œèˆ‡ auth.js é…åˆå‚³é€è³‡æ–™ã€‚
- tetris_game.htmlã€parkour_game.htmlï¼šéŠæˆ²é é¢ç”¨ä¾†æäº¤åˆ†æ•¸ï¼Œå¾Œç«¯ä½¿ç”¨ Score æ¨¡å‹å„²å­˜æ•¸æ“šã€‚
"""
